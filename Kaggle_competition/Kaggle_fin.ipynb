{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Challenge - Yelp Category Classification\n",
    "    \n",
    "Team:\n",
    "\n",
    "* Surendran Subbiah\n",
    "* Xuancheng Fan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model, model_selection\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import nltk \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import  PunktSentenceTokenizer\n",
    "from string import punctuation\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"yelp_data_official_training.csv\", delimiter=\"|\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47999, 3)\n"
     ]
    }
   ],
   "source": [
    "print (data.shape)\n",
    "data= data.reindex(np.random.permutation(data.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the word frequency in tf.idf ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train=data[\"Review Text\"][:42000]    # set train data \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=1, ngram_range=(1,2))\n",
    "x_data=vectorizer.fit_transform(x_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 967990)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[0].toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the train, dev data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train=data[\"Category\"][:42000]\n",
    "X_tr=x_data\n",
    "Y_tr=Y_train\n",
    "X_test=vectorizer.transform(data[\"Review Text\"][42001:])   # set test data\n",
    "Y_test=data[\"Category\"][42001:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters space and train the data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "clf=SGDClassifier()\n",
    "parameters={\"alpha\":np.linspace(0.000001,2)}\n",
    "gs_clf = GridSearchCV(clf, parameters, n_jobs=-1)\n",
    "gs_clf=gs_clf.fit(X_tr, Y_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5998\n"
     ]
    }
   ],
   "source": [
    "predicted=gs_clf.predict(X_test)\n",
    "accuracy= np.mean(predicted==Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89561904761904765"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the file ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_kaggle=pd.read_csv(\"yelp_data_official_test_nocategories.csv\",delimiter=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_kaggle.head()\n",
    "kaggle_text=data_kaggle[\"Review Text\"]\n",
    "kaggle_processed= vectorizer.transform(kaggle_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kaggle_predict=gs_clf.predict(kaggle_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000,)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.DataFrame({\"ID\": data_kaggle[\"ID\"]})\n",
    "submission[\"Category\"]=kaggle_predict\n",
    "submission[\"ID\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "### Brief Team Work ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Xuancheng built a test version with basic structure and simple algorithm to do the first submit.\n",
    "2. Surendran and Xuancheng respectively tried different methods\n",
    "3. Surendran's version got a better result at first.\n",
    "4. Based on Surendran's version, Xuancheng tested different feature and different setting and got the final result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Member's effort (except those in team work) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Surendran Subbiah ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I originally tried preprocessing the text of review to extract key noun phrases, lemmatize those and generate keyphrase bigrams which I had passed into the TfIdfvectorizer. However this method yielded 5 percentage points less accuracy as compared to passing in raw text to TFIDF vectorizer to generate unigram and bigram weighted frequency, based on which the final submissions to Kaggle were made. \n",
    "\n",
    "In our approach we used a Generalized linear model and Stochastic Gradient Descent Classifier as it was faster to perform hyperparameter search and cross validation using grid search as compared to other methods such as SVM with Polynomial and RBF Kernel. \n",
    "\n",
    "I also tried performing lifting of the features generated by TFIDF vectorizer, but the resulting matrix was dense and hence performing hyperparameter search proved to be computationaly intensive and infeasable. The lifting technique  I tried  was \n",
    "\n",
    "$$\\phi(x)=cos(G^Tx+b)$$\n",
    "\n",
    "It is my view that using a random non-linear function as above with very high regularization parameter can outperform all other techniques used by us. \n",
    "\n",
    "We reason that using a simple linear classfier gives accuracy levels near 90%, due to the linearly sepearble nature of documents especially after using TFIDF as feature preprocessing. TFIDF generates a sparse matrix with non-zero values attributed to terms and words that are unique to a particular document resulting in the effective linear seperability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xuancheng ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. My original thoght is to use wn.path_similarity to test the similarity of word to the keywords of 6 categories. For example, \"hair\" & \"salon\" would have a close distance to \"body\". So the review include these 2 words are likely to be classified as \"Beauty & Bath\".\n",
    "    Below is the function I use:\n",
    "$$\n",
    "def distance_feature(x, keyword):\n",
    "    try:\n",
    "        termlist = freq_normed_unigrams(x)# get top unigrams\n",
    "        distance = []\n",
    "        for term in termlist:                  # for each term\n",
    "            s = wn.synsets(term)               # get its nominal synsets\n",
    "            for syn in s:                   # for each lemma synset   \n",
    "                c = wn.path_similarity(wn.synset(syn.name()), wn.synset(keyword))\n",
    "                if c != None:\n",
    "                    distance.append(c)\n",
    "        if distance == []:\n",
    "            return 0\n",
    "        return max(distance)    \n",
    "    except TypeError:\n",
    "        return 0\n",
    "$$        \n",
    "2. However, the algorithm's expense is greatly huge. It usually need a whole night to get a accuracy result. And moreover, if using naive bayes, the result is not good enought.\n",
    "3. Thus, then I tried KNN but the algorithm's expense became even more huge. So I have to give up the similarity idea.\n",
    "4. Then I tried the frequency idea. Based on Suran's algorithm, I tried different feature and parameter settings to get the highest score. As a result, the highest dev accuracy I got is 0.90072709848121835 and the highest score in Kaggle is 0.88444.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
